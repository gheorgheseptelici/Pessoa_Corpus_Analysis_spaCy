{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65bbfb84-c9b3-4466-aa6a-ce1b34f2cb02",
   "metadata": {},
   "source": [
    "# Digital Corpus Processing of Fernando Pessoa's work with Python's spaCy module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27022396-9a96-4a16-9cff-6825967d159d",
   "metadata": {},
   "source": [
    "## Project description:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778486c1-e86c-434a-9db1-76912938f0a8",
   "metadata": {},
   "source": [
    "Fernando Pessoa was a Portuguese writer and one of the most important poets of the 20th century in Europe. An enigmatic figure, Pessoa's work is divided between his orthonymous writing and his writing under various aliases or, as he was calling them, heteronyms (of which there are around seventy-five). The writer firmly believed that there were multiple consciousnesses living inside him, each with their own biographies, passions and views on life. This is reflectled in the various themes and perspectives explored by Pessoa and his heteronyms in poetry and prose. For further reading on Pessoa and his heteronyms, https://poetrysociety.org/poems-essays/tributes/fernando-pessoa-his-heteronyms is a good resource.\n",
    "\n",
    "Unfortunately, a rather modest part of Pessoa's (or his heteronyms) body of work is translated into English and an even smaller part is available digitally. This project aims to incentivize digital humanities scholars, but also scholars from other disciplines who are interested in the computational analysis of large corpora of texts, to build a digital, annotated corpus of Pessoa and his heteronyms' work in order to open new avenues of exploring his writing using text processing and distant viewing techniques performed by digital humanists. \n",
    "\n",
    "An important digital resource of Pessoa's work can be found at https://www.pessoadigital.pt/en/index.html. While in Portuguese, this resource gathered a large part of Pessoa's (and his heteronyms') corpus and digitized them in machine readable format, along with each text's transcription. This resource could serve as a starting point for translating Pessoa's works into English and using annotation tools as the ones presented in the code below, in order to process and extract important linguistic features from his work. For speakers of Portuguese, the spaCy module that we will use in the code below (which for our case is set to the English pipeline) can be used with the Portuguese pipeline and perform similar tasks of text processing and annotation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee73e34e-5175-4f76-8ee7-4977aa003c2f",
   "metadata": {},
   "source": [
    "The nascent case that I present here uses three works originally written in English by Pessoa which were downloaded from Project Gutenberg. Already from this small dataset one can explore some textual features that are present in these three collections of poems and sonnets. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c0f37-1cf8-4797-91d6-875a17fdcd31",
   "metadata": {},
   "source": [
    "## Processing steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b4087a-3439-4120-8d4b-fd81755817ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the following modules from the command prompt or Anaconda Navigator if you do not have them installed already \n",
    "# pip install spacy\n",
    "\n",
    "# pip install pandas \n",
    "# pip install plotly\n",
    "# pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf547eb-9b21-4cda-9553-ae6153b67430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the gutenberg-cleaner package for cleaning gutenberg texts \n",
    "# pip install gutenberg-cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ba929-ecd5-4451-885e-32217d7a10aa",
   "metadata": {},
   "source": [
    "To begin, let's import the needed Python modules that will be used to operate with our dataset and transform them into DataFrame objects. Furthermore, let's implement the spaCy module and install the simple English Language model that we will be used for the text processing tasks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d2a371d-aa9d-4ff9-9b3b-1ed57b86c9e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 39.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.6/12.8 MB 39.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 28.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\envs\\myenvironment\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "# Install English language model\n",
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff14a25a-2543-419e-9a32-ce9768e8c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os to upload documents and metadata\n",
    "import os\n",
    "\n",
    "# Load spaCy visualizer\n",
    "from spacy import displacy\n",
    "\n",
    "# Import pandas DataFrame packages\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f750074-30bc-4392-9f51-5c30da07bdd0",
   "metadata": {},
   "source": [
    "In this step we will write some code to access the folder where our corpus is. Note that if you work with your own files then you have to add them to the folder of the corpus or change the directory from which Python will access and read the texts. After setting the correct directories add the filenames and the content of the files to two separate lists. As a last step, create a dictionary object that will assign each text to its corresponding filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea78af00-bb70-4802-a293-4dd99d4c6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists for file names and contents\n",
    "texts = []\n",
    "file_names = []\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for _file_name in os.listdir('data'):\n",
    "# Look for only text files\n",
    "    if _file_name.endswith('.txt'):\n",
    "    # Append contents of each text file to text list\n",
    "        texts.append(open('data' + '/' + _file_name, 'r', encoding='utf-8').read())\n",
    "        # Append name of each file to file name list\n",
    "        file_names.append(_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34be2f23-fc05-41fd-b604-a885800f38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary object associating each file name with its text\n",
    "d = {'Filename':file_names,'Document':texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c523eae1-1170-4351-b0e6-7bb9f46e0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import simple_cleaner module from gutenberg-cleaner\n",
    "from gutenberg_cleaner import simple_cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e449c-6436-4d2c-8e62-ed34b2f1fe70",
   "metadata": {},
   "source": [
    "Now we can turn our cleaned corpus into a DataFrame object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17631e93-779b-48ee-8cb7-cbba115a723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dictionary into a dataframe\n",
    "text_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a13649f-b115-41ad-8aea-16bba8952d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19978.txt</td>\n",
       "      <td>﻿The Project Gutenberg eBook of 35 Sonnets\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66039.txt</td>\n",
       "      <td>﻿The Project Gutenberg eBook of English Poems,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66040.txt</td>\n",
       "      <td>﻿The Project Gutenberg eBook of English Poems,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename                                           Document\n",
       "0  19978.txt  ﻿The Project Gutenberg eBook of 35 Sonnets\\n  ...\n",
       "1  66039.txt  ﻿The Project Gutenberg eBook of English Poems,...\n",
       "2  66040.txt  ﻿The Project Gutenberg eBook of English Poems,..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the result\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5f9cd-4a03-4eb2-b445-68f3b47bdd7d",
   "metadata": {},
   "source": [
    "Since our corpus is downloaded from Project Gutenberg, we need to slightly clean it up before doing any text processing on it. Project Gutenberg downloads contain other information in the .txt files besides the raw text, thus we will use the simple_cleaner package from the gutenberg_cleaner module in order to tidy up our texts and remove information that is not necessary for the task we want to perform. The raw text will be added to a new column in the DataFrame in order to also preserve the documents in their original state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "135b3627-61a5-4c63-8fe8-196bfb13fd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Document</th>\n",
       "      <th>Raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19978.txt</td>\n",
       "      <td>﻿The Project Gutenberg eBook of 35 Sonnets\\n  ...</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n\\r\\n35 Sonnets\\r\\n\\r\\nby Fernando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66039.txt</td>\n",
       "      <td>﻿The Project Gutenberg eBook of English Poems,...</td>\n",
       "      <td>\\r\\nENGLISH\\r\\nPOEMS\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nBY\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66040.txt</td>\n",
       "      <td>﻿The Project Gutenberg eBook of English Poems,...</td>\n",
       "      <td>ENGLISH\\r\\nPOEMS\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nBY\\r\\nFERN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename                                           Document  \\\n",
       "0  19978.txt  ﻿The Project Gutenberg eBook of 35 Sonnets\\n  ...   \n",
       "1  66039.txt  ﻿The Project Gutenberg eBook of English Poems,...   \n",
       "2  66040.txt  ﻿The Project Gutenberg eBook of English Poems,...   \n",
       "\n",
       "                                            Raw_text  \n",
       "0  \\r\\n\\r\\n\\r\\n\\r\\n35 Sonnets\\r\\n\\r\\nby Fernando ...  \n",
       "1  \\r\\nENGLISH\\r\\nPOEMS\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nBY\\r\\n...  \n",
       "2  ENGLISH\\r\\nPOEMS\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nBY\\r\\nFERN...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['Raw_text'] = text_df['Document'].apply(simple_cleaner)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1142c50a-1698-417b-8240-dcc42e93a081",
   "metadata": {},
   "source": [
    "Upon inspection, one can notice that the text still contains some characters that we would like to avoid for our processing purposes. Let's get rid of them and also of the '.txt' extension at the end of our filenames.\n",
    "\n",
    "Note: if for some reason you feel like the presence of certain characters, like the new line (\\n), are relevant for your analysis, just remove the line of code below that deletes these characters from our texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9149e549-3c2f-4232-a889-4dff7ce10adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Document</th>\n",
       "      <th>Raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19978</td>\n",
       "      <td>﻿The Project Gutenberg eBook of 35 Sonnets\\n  ...</td>\n",
       "      <td>35 Sonnets    by Fernando Pessoa          I.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66039</td>\n",
       "      <td>﻿The Project Gutenberg eBook of English Poems,...</td>\n",
       "      <td>ENGLISH  POEMS          BY    FERNANDO PESSOA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66040</td>\n",
       "      <td>﻿The Project Gutenberg eBook of English Poems,...</td>\n",
       "      <td>ENGLISH  POEMS          BY  FERNANDO PESSOA   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename                                           Document  \\\n",
       "0    19978  ﻿The Project Gutenberg eBook of 35 Sonnets\\n  ...   \n",
       "1    66039  ﻿The Project Gutenberg eBook of English Poems,...   \n",
       "2    66040  ﻿The Project Gutenberg eBook of English Poems,...   \n",
       "\n",
       "                                            Raw_text  \n",
       "0  35 Sonnets    by Fernando Pessoa          I.  ...  \n",
       "1  ENGLISH  POEMS          BY    FERNANDO PESSOA ...  \n",
       "2  ENGLISH  POEMS          BY  FERNANDO PESSOA   ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted characters from the text. \n",
    "text_df['Raw_text'] = text_df['Raw_text'].str.replace('\\r', ' ', regex=True).str.strip()\n",
    "text_df['Raw_text'] = text_df['Raw_text'].str.replace('\\t', ' ', regex=True).str.strip()\n",
    "text_df['Raw_text'] = text_df['Raw_text'].str.replace('\\n', ' ', regex=True).str.strip()\n",
    "# Remove .txt from title of each paper\n",
    "text_df['Filename'] = text_df['Filename'].str.replace('.txt', '', regex=True)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328bc22a-e431-4337-9ecc-49c011504a4a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "We can now proceed with loading the metadata for the three texts in our corpus. This can be done by downloading the metadata .csv file from the Gutenberg website (called pg_catalog.csv) and writing some code that will select only the metadata of the texts that we include in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8414780-1ecd-4084-816b-0ac7560db197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Gutenberg metadata csv\n",
    "metadata_df = pd.read_csv('pg_catalog.csv')\n",
    "\n",
    "# List of Gutenberg IDs for the chosen books\n",
    "chosen_book_ids = [19978, 66039, 66040]  # Extract only the metadata for the three texts by Pessoa in our corpus\n",
    "\n",
    "# Filter the DataFrame to include only rows with these IDs\n",
    "filtered_metadata = metadata_df[metadata_df['Text#'].isin(chosen_book_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67767b42-052d-42e8-b5db-c97c295d9e47",
   "metadata": {},
   "source": [
    "Print the new filtered_metadata to inspect if our code worked properly. If yes, then we now have the required metadata for the works in our corpus and we can export it to a '.csv' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b691d165-30fb-4be4-b154-0fb66a218d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Text#  Type      Issued                            Title Language  \\\n",
      "19907  19978  Text  2006-11-30                       35 Sonnets       en   \n",
      "65960  66039  Text  2021-08-11  English Poems, Volume 01 (of 2)       en   \n",
      "65961  66040  Text  2021-08-11  English Poems, Volume 02 (of 2)       en   \n",
      "\n",
      "                           Authors Subjects LoCC  \\\n",
      "19907  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
      "65960  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
      "65961  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
      "\n",
      "                                  Bookshelves  \n",
      "19907  Browsing: Literature; Browsing: Poetry  \n",
      "65960  Browsing: Literature; Browsing: Poetry  \n",
      "65961  Browsing: Literature; Browsing: Poetry  \n"
     ]
    }
   ],
   "source": [
    "# Display the filtered metadata\n",
    "print(filtered_metadata)\n",
    "\n",
    "# Save the filtered metadata to a new CSV\n",
    "filtered_metadata.to_csv('pessoa_gutenberg_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f5b315-91ac-477c-b972-cfc7a563104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text#</th>\n",
       "      <th>Type</th>\n",
       "      <th>Issued</th>\n",
       "      <th>Title</th>\n",
       "      <th>Language</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>LoCC</th>\n",
       "      <th>Bookshelves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19978</td>\n",
       "      <td>Text</td>\n",
       "      <td>2006-11-30</td>\n",
       "      <td>35 Sonnets</td>\n",
       "      <td>en</td>\n",
       "      <td>Pessoa, Fernando, 1888-1935</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>PQ</td>\n",
       "      <td>Browsing: Literature; Browsing: Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66039</td>\n",
       "      <td>Text</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>English Poems, Volume 01 (of 2)</td>\n",
       "      <td>en</td>\n",
       "      <td>Pessoa, Fernando, 1888-1935</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>PQ</td>\n",
       "      <td>Browsing: Literature; Browsing: Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66040</td>\n",
       "      <td>Text</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>English Poems, Volume 02 (of 2)</td>\n",
       "      <td>en</td>\n",
       "      <td>Pessoa, Fernando, 1888-1935</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>PQ</td>\n",
       "      <td>Browsing: Literature; Browsing: Poetry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Text#  Type      Issued                            Title Language  \\\n",
       "0  19978  Text  2006-11-30                       35 Sonnets       en   \n",
       "1  66039  Text  2021-08-11  English Poems, Volume 01 (of 2)       en   \n",
       "2  66040  Text  2021-08-11  English Poems, Volume 02 (of 2)       en   \n",
       "\n",
       "                       Authors Subjects LoCC  \\\n",
       "0  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
       "1  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
       "2  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
       "\n",
       "                              Bookshelves  \n",
       "0  Browsing: Literature; Browsing: Poetry  \n",
       "1  Browsing: Literature; Browsing: Poetry  \n",
       "2  Browsing: Literature; Browsing: Poetry  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the newly created pessoa_metadata.csv to the metadata dataframe\n",
    "metadata_df = pd.read_csv('pessoa_gutenberg_metadata.csv')\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b476b7d9-0ef5-4ca1-b7e2-c6d68460b829",
   "metadata": {},
   "source": [
    "In order to merge the two DataFrames that we have created until this point we need to create a common column upon which the merge will be executed. Let's rename the 'Text#' column in our metadata_df to 'Filename' in order to match the 'Filename' column in the text_df. Another issue that we need to take care of before merging is that the data type for 'Text#' in our .csv file downloaded from Project Gutenberg is integer while the one in 'Title' column in our text_df is a string. To solve this we will convert the datatype in our metadata_df to strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e10f0c57-44e8-48be-b900-af1fa78ea840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Type</th>\n",
       "      <th>Issued</th>\n",
       "      <th>Title</th>\n",
       "      <th>Language</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>LoCC</th>\n",
       "      <th>Bookshelves</th>\n",
       "      <th>Document</th>\n",
       "      <th>Raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19978</td>\n",
       "      <td>Text</td>\n",
       "      <td>2006-11-30</td>\n",
       "      <td>35 Sonnets</td>\n",
       "      <td>en</td>\n",
       "      <td>Pessoa, Fernando, 1888-1935</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>PQ</td>\n",
       "      <td>Browsing: Literature; Browsing: Poetry</td>\n",
       "      <td>﻿The Project Gutenberg eBook of 35 Sonnets\\n  ...</td>\n",
       "      <td>35 Sonnets    by Fernando Pessoa          I.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66039</td>\n",
       "      <td>Text</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>English Poems, Volume 01 (of 2)</td>\n",
       "      <td>en</td>\n",
       "      <td>Pessoa, Fernando, 1888-1935</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>PQ</td>\n",
       "      <td>Browsing: Literature; Browsing: Poetry</td>\n",
       "      <td>﻿The Project Gutenberg eBook of English Poems,...</td>\n",
       "      <td>ENGLISH  POEMS          BY    FERNANDO PESSOA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66040</td>\n",
       "      <td>Text</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>English Poems, Volume 02 (of 2)</td>\n",
       "      <td>en</td>\n",
       "      <td>Pessoa, Fernando, 1888-1935</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>PQ</td>\n",
       "      <td>Browsing: Literature; Browsing: Poetry</td>\n",
       "      <td>﻿The Project Gutenberg eBook of English Poems,...</td>\n",
       "      <td>ENGLISH  POEMS          BY  FERNANDO PESSOA   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename  Type      Issued                            Title Language  \\\n",
       "0    19978  Text  2006-11-30                       35 Sonnets       en   \n",
       "1    66039  Text  2021-08-11  English Poems, Volume 01 (of 2)       en   \n",
       "2    66040  Text  2021-08-11  English Poems, Volume 02 (of 2)       en   \n",
       "\n",
       "                       Authors Subjects LoCC  \\\n",
       "0  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
       "1  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
       "2  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
       "\n",
       "                              Bookshelves  \\\n",
       "0  Browsing: Literature; Browsing: Poetry   \n",
       "1  Browsing: Literature; Browsing: Poetry   \n",
       "2  Browsing: Literature; Browsing: Poetry   \n",
       "\n",
       "                                            Document  \\\n",
       "0  ﻿The Project Gutenberg eBook of 35 Sonnets\\n  ...   \n",
       "1  ﻿The Project Gutenberg eBook of English Poems,...   \n",
       "2  ﻿The Project Gutenberg eBook of English Poems,...   \n",
       "\n",
       "                                            Raw_text  \n",
       "0  35 Sonnets    by Fernando Pessoa          I.  ...  \n",
       "1  ENGLISH  POEMS          BY    FERNANDO PESSOA ...  \n",
       "2  ENGLISH  POEMS          BY  FERNANDO PESSOA   ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename column from Title to Filename in order to merge the two tables\n",
    "metadata_df.rename(columns={\"Text#\": \"Filename\"}, inplace=True)\n",
    "\n",
    "# Convert the data type of the Filename column into strings to allow the merging of the metadata and text tables in the next step\n",
    "metadata_df['Filename'] = metadata_df['Filename'].astype(str)\n",
    "\n",
    "# Merge the files to their metadata in a new DataFrame\n",
    "pessoa_df = metadata_df.merge(text_df,on='Filename')\n",
    "pessoa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca5bee8-55bd-40b6-88ad-3da127f85e19",
   "metadata": {},
   "source": [
    "Now we can save our merged DataFrame that containts both the metadata of each text in our corpus as well as the content of each file into a new '.csv' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "061e6fa6-3e47-4bb2-8c0e-73e82c77a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged DataFrame as csv to your computer's working directory\n",
    "pessoa_df.to_csv('Metadata_and_full_texts.csv', encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3e385e-842a-4984-8f0f-6d903d8485ed",
   "metadata": {},
   "source": [
    "After merging the two dataframes we can start with processing the content of our DataFrames using spaCy. See the Notebook at https://github.com/yevgenm/corpus-analysis-spacy/ for a detailed description of all the steps that are performed in the following lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e17970c0-86c9-4765-ae53-e74e66a23a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Load nlp pipeline\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Check what functions it performs\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5e486c6-2402-4b92-90b7-95e93240381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that runs the nlp pipeline on any given input text\n",
    "def process_text(text):\n",
    "    return nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60f57500-031a-49e0-b798-b1fc50d70190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Type</th>\n",
       "      <th>Issued</th>\n",
       "      <th>Title</th>\n",
       "      <th>Language</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>LoCC</th>\n",
       "      <th>Bookshelves</th>\n",
       "      <th>Document</th>\n",
       "      <th>Raw_text</th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19978</td>\n",
       "      <td>Text</td>\n",
       "      <td>2006-11-30</td>\n",
       "      <td>35 Sonnets</td>\n",
       "      <td>en</td>\n",
       "      <td>Pessoa, Fernando, 1888-1935</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>PQ</td>\n",
       "      <td>Browsing: Literature; Browsing: Poetry</td>\n",
       "      <td>﻿The Project Gutenberg eBook of 35 Sonnets\\n  ...</td>\n",
       "      <td>35 Sonnets    by Fernando Pessoa          I.  ...</td>\n",
       "      <td>(35, Sonnets,    , by, Fernando, Pessoa,      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66039</td>\n",
       "      <td>Text</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>English Poems, Volume 01 (of 2)</td>\n",
       "      <td>en</td>\n",
       "      <td>Pessoa, Fernando, 1888-1935</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>PQ</td>\n",
       "      <td>Browsing: Literature; Browsing: Poetry</td>\n",
       "      <td>﻿The Project Gutenberg eBook of English Poems,...</td>\n",
       "      <td>ENGLISH  POEMS          BY    FERNANDO PESSOA ...</td>\n",
       "      <td>(ENGLISH,  , POEMS,          , BY,    , FERNAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66040</td>\n",
       "      <td>Text</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>English Poems, Volume 02 (of 2)</td>\n",
       "      <td>en</td>\n",
       "      <td>Pessoa, Fernando, 1888-1935</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>PQ</td>\n",
       "      <td>Browsing: Literature; Browsing: Poetry</td>\n",
       "      <td>﻿The Project Gutenberg eBook of English Poems,...</td>\n",
       "      <td>ENGLISH  POEMS          BY  FERNANDO PESSOA   ...</td>\n",
       "      <td>(ENGLISH,  , POEMS,          , BY,  , FERNANDO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename  Type      Issued                            Title Language  \\\n",
       "0    19978  Text  2006-11-30                       35 Sonnets       en   \n",
       "1    66039  Text  2021-08-11  English Poems, Volume 01 (of 2)       en   \n",
       "2    66040  Text  2021-08-11  English Poems, Volume 02 (of 2)       en   \n",
       "\n",
       "                       Authors Subjects LoCC  \\\n",
       "0  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
       "1  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
       "2  Pessoa, Fernando, 1888-1935   Poetry   PQ   \n",
       "\n",
       "                              Bookshelves  \\\n",
       "0  Browsing: Literature; Browsing: Poetry   \n",
       "1  Browsing: Literature; Browsing: Poetry   \n",
       "2  Browsing: Literature; Browsing: Poetry   \n",
       "\n",
       "                                            Document  \\\n",
       "0  ﻿The Project Gutenberg eBook of 35 Sonnets\\n  ...   \n",
       "1  ﻿The Project Gutenberg eBook of English Poems,...   \n",
       "2  ﻿The Project Gutenberg eBook of English Poems,...   \n",
       "\n",
       "                                            Raw_text  \\\n",
       "0  35 Sonnets    by Fernando Pessoa          I.  ...   \n",
       "1  ENGLISH  POEMS          BY    FERNANDO PESSOA ...   \n",
       "2  ENGLISH  POEMS          BY  FERNANDO PESSOA   ...   \n",
       "\n",
       "                                                 Doc  \n",
       "0  (35, Sonnets,    , by, Fernando, Pessoa,      ...  \n",
       "1  (ENGLISH,  , POEMS,          , BY,    , FERNAN...  \n",
       "2  (ENGLISH,  , POEMS,          , BY,  , FERNANDO...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to the \"Raw_text\" column, so that the nlp pipeline is called on each of the three Pessoa works in our corpus\n",
    "pessoa_df['Doc'] = pessoa_df['Raw_text'].apply(process_text)\n",
    "pessoa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e9fd584-9bbf-4837-852c-abdd24c07319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve tokens from a doc object\n",
    "def get_token(doc):\n",
    "    return [(token.text) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b6bc12c-001d-4a7f-b9d0-413332682aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the token retrieval function on the doc objects in the dataframe\n",
    "pessoa_df['Tokens'] = pessoa_df['Doc'].apply(get_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db595385-72fb-40eb-a9df-19ba94094647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35 Sonnets</td>\n",
       "      <td>[35, Sonnets,    , by, Fernando, Pessoa,      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English Poems, Volume 01 (of 2)</td>\n",
       "      <td>[ENGLISH,  , POEMS,          , BY,    , FERNAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English Poems, Volume 02 (of 2)</td>\n",
       "      <td>[ENGLISH,  , POEMS,          , BY,  , FERNANDO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title  \\\n",
       "0                       35 Sonnets   \n",
       "1  English Poems, Volume 01 (of 2)   \n",
       "2  English Poems, Volume 02 (of 2)   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [35, Sonnets,    , by, Fernando, Pessoa,      ...  \n",
       "1  [ENGLISH,  , POEMS,          , BY,    , FERNAN...  \n",
       "2  [ENGLISH,  , POEMS,          , BY,  , FERNANDO...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the list of tokens in each text within the corpus\n",
    "tokens = pessoa_df[['Title', 'Tokens']].copy()\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88395fb8-b0f3-480c-9824-9588e790315a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a function to retrieve lemmas from a doc object\n",
    "def get_lemma(doc):\n",
    "    return [(token.lemma_) for token in doc]\n",
    "\n",
    "# Run the lemma retrieval function on the doc objects in the dataframe\n",
    "pessoa_df['Lemmas'] = pessoa_df['Doc'].apply(get_lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8f2c0da-f3ac-457e-b848-1a8b59a5c76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35 Sonnets</td>\n",
       "      <td>[35, sonnet,    , by, Fernando, Pessoa,       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English Poems, Volume 01 (of 2)</td>\n",
       "      <td>[ENGLISH,  , poems,          , by,    , FERNAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English Poems, Volume 02 (of 2)</td>\n",
       "      <td>[ENGLISH,  , poems,          , by,  , FERNANDO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title  \\\n",
       "0                       35 Sonnets   \n",
       "1  English Poems, Volume 01 (of 2)   \n",
       "2  English Poems, Volume 02 (of 2)   \n",
       "\n",
       "                                              Lemmas  \n",
       "0  [35, sonnet,    , by, Fernando, Pessoa,       ...  \n",
       "1  [ENGLISH,  , poems,          , by,    , FERNAN...  \n",
       "2  [ENGLISH,  , poems,          , by,  , FERNANDO...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the lemmas of the words found in each text\n",
    "lemmas = pessoa_df[['Title', 'Lemmas']].copy()\n",
    "lemmas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f92dd91-ad39-43e2-970f-4b0a22687628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve part-of-speech from a doc object\n",
    "def get_pos(doc):\n",
    "    #Return the coarse- and fine-grained part of speech text for each token in the doc\n",
    "    return [(token.pos_, token.tag_) for token in doc]\n",
    "\n",
    "# Define a function to retrieve parts of speech from a doc object\n",
    "pessoa_df['POS'] = pessoa_df['Doc'].apply(get_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42167bda-ce72-4441-b2c0-b2c5ad63ff8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35 Sonnets</td>\n",
       "      <td>[(NUM, CD), (NOUN, NNS), (SPACE, _SP), (ADP, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English Poems, Volume 01 (of 2)</td>\n",
       "      <td>[(PROPN, NNP), (SPACE, _SP), (NOUN, NN), (SPAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English Poems, Volume 02 (of 2)</td>\n",
       "      <td>[(PROPN, NNP), (SPACE, _SP), (NOUN, NN), (SPAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title  \\\n",
       "0                       35 Sonnets   \n",
       "1  English Poems, Volume 01 (of 2)   \n",
       "2  English Poems, Volume 02 (of 2)   \n",
       "\n",
       "                                                 POS  \n",
       "0  [(NUM, CD), (NOUN, NNS), (SPACE, _SP), (ADP, I...  \n",
       "1  [(PROPN, NNP), (SPACE, _SP), (NOUN, NN), (SPAC...  \n",
       "2  [(PROPN, NNP), (SPACE, _SP), (NOUN, NN), (SPAC...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the POS found in each text within the corpus\n",
    "pos = pessoa_df[['Title', 'POS']].copy()\n",
    "pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d20510dd-149b-47e1-a305-e0b334439118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract proper nouns from Doc object\n",
    "def extract_verbs(doc):\n",
    "    return [token.text for token in doc if token.pos_ == 'VERB']\n",
    "\n",
    "# Apply function to Doc column and store resulting proper nouns in new column\n",
    "pessoa_df['Verbs'] = pessoa_df['Doc'].apply(extract_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee82a8ef-4f42-4d2a-8f39-d7bc7c957489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35 Sonnets</td>\n",
       "      <td>[write, speak, do, look, transfused, give, ges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English Poems, Volume 01 (of 2)</td>\n",
       "      <td>[published, meant, annul, supersede, published...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English Poems, Volume 02 (of 2)</td>\n",
       "      <td>[Set, come, Let, tell, comparing, lay, awaking...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title  \\\n",
       "0                       35 Sonnets   \n",
       "1  English Poems, Volume 01 (of 2)   \n",
       "2  English Poems, Volume 02 (of 2)   \n",
       "\n",
       "                                               Verbs  \n",
       "0  [write, speak, do, look, transfused, give, ges...  \n",
       "1  [published, meant, annul, supersede, published...  \n",
       "2  [Set, come, Let, tell, comparing, lay, awaking...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display just the title of the work in the corpus and the lemmatized verbs present in it.\n",
    "verbs = pessoa_df[['Title', 'Verbs']].copy()\n",
    "verbs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2cb440-86f5-4ca8-83fc-fe9c96d13697",
   "metadata": {},
   "source": [
    "After all the processing is done it is sensible to export the complete DataFrame into a final '.csv' file in case someone wants to just read it with Pandas in their own environment and perform further processing without repeating the steps done in this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1049db55-ac24-4227-ad58-1cde43ea24ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final DataFrame with all its columns as a CSV file\n",
    "pessoa_df.to_csv('Corpus_data_and_annotations.csv', index=False, encoding='utf-8', header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
